{
    "model_name_or_path": "/lite-ai/mistral-1.1B",
    "deepspeed": "./train_args/ds_config.json",
    "data_config": "./train_args/data_info.ini",
    "per_device_eval_batch_size": 64,
    "gradient_clipping": 1.0,
    "num_grad_accum_steps": 64,
    "seed": 666,
    "use_cache": false,
    "cache_path": "",
    "weight_decay": 0.1,
    "learning_rate": 5e-05,
    "lr_scheduler_type": "constant",
    "warmup_proportion": 0.001,
    "num_train_epochs": 4,
    "log_path": "/root/MutilNode/distillation/log",
    "saving_steps": 1000,
    "model_output_dir": "/home/mutil/train_model",
    "offload": false,
    "resume": false,
    "resume_model_path": "/home/mutil/train_model",
    "eval_step": 200,
    "do_eval": false,
    "version": 1,
    "tokenize_num_workers": 16,
    "per_device_train_batch_size": 16,
    "max_seq_length": 2048,
    "logging_steps": 100,
    "save_total_limit": 1,
    "warmup_ratio": 0.01,
    "gradient_checkpointing": true,
    "logging_first_step": false,
    "disable_tqdm": false,
    "fp16": false,
    "bf16": true,
    "report_to": "tensorboard",
    "dataloader_num_workers": 0,
    "save_strategy": "steps",
    "max_grad_norm": 1.0,
    "train_dype": "fp8",
    "remove_unused_columns": false
}